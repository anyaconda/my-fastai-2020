{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta 1/3/2020 My fast.ai Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Course: Practical Deep Learning for Coders.  https://course.fast.ai\n",
    "##### Deep Learning for Coders with fastai & PyTorch Book Chapters and Related Resources\n",
    "* [All book chapters](https://github.com/fastai/fastbook) -- the Fast.ai book as iPython notebooks\n",
    "* [MOOC](https://course.fast.ai/) -- Includes videos, setup instructions, etc.\n",
    "\n",
    "Documentation: https://docs.fast.ai\n",
    "# my-fastai-2020 Documentation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1. Data Prep\n",
    "`DataBlock`, `DataLoaders`, `DataLoader`, `Dataset` and `Datasets` classes\n",
    " \n",
    "\n",
    "### 1.1 From Data to DataLoaders\n",
    "Src: [Book Chapter 2. From Model to Production](https://github.com/fastai/fastbook/blob/master/02_production.ipynb) pg. 69-74  \n",
    "We need to assemble data in a format suitable for model training. In fastai, that means creating an object called `DataLoaders`.  It provides the data for your model.\n",
    "\n",
    "\n",
    "> DataLoaders: A fastai class that stores multiple `DataLoader` objects you pass to it, normally a `train` and a `valid` (it's possible to have as many as you like). The first two are made available as properties.\n",
    "\n",
    "A `DataLoaders` includes validation and training `DataLoader`s. \n",
    ">DataLoader: a class that provides batches of a few items at a time to the GPU. When you loop through a `DataLoader` fastai will give you 64 (by default) items at a time, all stacked up into a single tensor. We can view a few of those items with the `show_batch` method on a `DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn downloaded data into a `DataLoaders` object we need to tell fastai at least four things:\n",
    "\n",
    "- What kinds of data we are working with\n",
    "- How to get the list of items\n",
    "- How to label these items\n",
    "- How to create the validation set\n",
    "\n",
    "A number of *factory methods* for particular combinations of these things, which are convenient when you have an application and data structure that happen to fit into those predefined methods. \n",
    "\n",
    "`DataBlock`  \n",
    "For when you don't, fastai has an extremely flexible system called the *data block API*. With this API you can fully customize every stage of the creation of your `DataLoaders`. \n",
    "> DataBlock:  like a template for creating a `DataLoaders`. \n",
    "\n",
    "Here is what we need to create a `DataLoaders` for the dataset that we just downloaded:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "bears = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), #specify types for the independent and dependent variables\n",
    "    get_items=get_image_files, #get a list of file paths\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42), #split our training and validation sets randomly\n",
    "    get_y=parent_label, #create the labels \n",
    "    item_tfms=Resize(128)) #a transform, resizes the images to the same size, needed to form mini-batches\n",
    "\n",
    "dls = bears.dataloaders(path) #provide the path for the images\n",
    "dls.valid.show_batch(max_n=4, nrows=1) #look at items in DataLoader\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_image_files` function takes a path, and returns a list of all of the images in that path (recursively, by default)  \n",
    "`parent_label` is a function provided by fastai that simply gets the name of the folder a file is in. Because we put each of our bear images into folders based on the type of bear, this is going to give us the labels that we need.\n",
    "\n",
    "*Item transforms*: \n",
    "Pieces of code that run on each individual item, whether it be an image, category, or so forth. fastai includes many predefined transforms:  \n",
    "`Resize` crops the images to fit a square shape of the size requested, using the full width or height. This can result in losing some important details.  \n",
    "`RandomResizedCrop` provides images where the objects are in slightly different places and slightly different sizes. The most important parameter to pass in is `min_scale`, which determines how much of the image to select at minimum each time.  \n",
    "Alternatively, you can ask fastai to pad the images with zeros (black), or squish/stretch them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "bears = bears.new(item_tfms=RandomResizedCrop(128, min_scale=0.3))\n",
    "dls = bears.dataloaders(path)\n",
    "dls.train.show_batch(max_n=4, nrows=1, unique=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1a Data Augmentation\n",
    "Creating random variations of our input data, such that they appear different, but do not actually change the meaning of the data. Examples of common data augmentation techniques for images are rotation, flipping, perspective warping, brightness changes and contrast changes. For natural photo images a standard set of augmentations is provided with the `aug_transforms` function. Because our images are now all the same size, we can apply these augmentations to an entire batch of them using the GPU, which will save a lot of time. To tell fastai we want to use these transforms on a batch, we use the `batch_tfms` parameter (note that we're not using `RandomResizedCrop` in this example; we're also using double the amount of augmentation compared to the default):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "bears = bears.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=2))\n",
    "dls = bears.dataloaders(path)\n",
    "dls.train.show_batch(max_n=8, nrows=2, unique=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
